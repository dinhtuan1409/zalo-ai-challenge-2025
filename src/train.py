import os
import math
import torch
import random
import numpy as np
import torch.nn as nn
from torch.utils.data import DataLoader, Subset
from tqdm import tqdm
from torch.cuda.amp import autocast, GradScaler

# --- Import c√°c file code c·ªßa b·∫°n ---
# (Gi·∫£ s·ª≠ ch√∫ng n·∫±m trong c√°c file .py t∆∞∆°ng ·ª©ng)
from dataset import FeatureVideoQADatasetMPNET, collate_fn_mpnet, load_text_encoder
from model import EarlyFusionMPNetQA 

# ===========================
# CONFIG
# ===========================
DATA_JSON = "/kaggle/input/zalo-ai-challenge-2025-roadbuddy/traffic_buddy_train+public_test/train/train.json"
VIDEO_FEAT_DIR = "Feature/train"

# ‚ùó S·ª¨A L·ªñI: ƒê·ªìng b·ªô video_dim ·ªü ƒë√¢y
VIDEO_FEAT_DIM = 2304 # C·∫ßn kh·ªõp v·ªõi feature c·ªßa b·∫°n (dataset ƒëang l√† 2304)

BATCH_SIZE = 16
LR = 3e-4
EPOCHS = 15
WEIGHT_DECAY = 0.01
VALID_SPLIT = 0.1
OUTPUT_DIR = "/kaggle/working/"

SEED = 42
USE_FP16 = True
ACCUM_STEPS = 1
EARLYSTOP_PATIENCE = 3
CLIP_NORM = 1.0

# üí° T·ªêI ∆ØU: TƒÉng t·ªëc ƒë·ªô load data
NUM_WORKERS = os.cpu_count() # S·ª≠ d·ª•ng t·∫•t c·∫£ c√°c CPU core

# ===========================
# SEED
# ===========================
def seed_everything(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# ===========================
# EVALUATE
# ===========================
def evaluate(model, loader, loss_fn, device):
    """
    T√≠nh to√°n loss v√† accuracy tr√™n t·∫≠p validation.
    """
    model.eval()
    total_loss = 0.0
    total_correct = 0
    total_samples = 0

    with torch.no_grad():
        # üí° T·ªêI ∆ØU: Th√™m leave=False ƒë·ªÉ thanh tqdm eval t·ª± x√≥a
        pbar = tqdm(loader, desc="Eval", leave=False)
        for batch in pbar:
            video = batch["video_feats"].to(device)
            text = batch["text_feats"].to(device)
            labels = batch["labels"].to(device)

            # üí° T·ªêI ∆ØU: Ch·∫°y eval v·ªõi autocast
            with autocast(enabled=USE_FP16):
                logits = model(video, text)
                
                # üí° T·ªêI ∆ØU: D√πng loss_fn ƒë√£ kh·ªüi t·∫°o (v·ªõi ignore_index)
                loss = loss_fn(logits, labels)

            total_loss += loss.item() * video.size(0)
            
            # --- T√≠nh accuracy (gi·ªØ nguy√™n logic mask c·ªßa b·∫°n) ---
            preds = logits.argmax(dim=1)
            
            # üí° T·ªêI ∆ØU: ignore_index=-1 cho c·∫£ accuracy
            mask = labels != -1 
            if mask.sum() > 0:
                total_correct += (preds[mask] == labels[mask]).sum().item()
                total_samples += mask.sum().item()

    avg_loss = total_loss / len(loader.dataset)
    avg_acc = total_correct / total_samples if total_samples > 0 else 0.0
    return avg_loss, avg_acc

# ===========================
# MAIN TRAIN LOOP
# ===========================
def train_loop():
    seed_everything()
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # --------------------------
    # Load dataset
    # üí° T·ªêI ∆ØU: Load text_encoder 1 L·∫¶N duy nh·∫•t ·ªü main
    # --------------------------
    print("Loading text encoder...")
    text_encoder = load_text_encoder(device)
    
    print("Loading dataset...")
    full_ds = FeatureVideoQADatasetMPNET(
        json_path=DATA_JSON,
        video_feat_dir=VIDEO_FEAT_DIR,
        video_feat_dim=VIDEO_FEAT_DIM, # ‚ùó S·ª¨A L·ªñI: Truy·ªÅn video_dim v√†o dataset
        text_encoder=text_encoder,     # Truy·ªÅn encoder ƒë√£ load
        preload_text=True,
        is_test=False
    )

    n = len(full_ds)
    n_val = max(1, int(n * VALID_SPLIT))

    indices = list(range(n))
    random.shuffle(indices)
    val_idx = indices[:n_val]
    train_idx = indices[n_val:]

    train_ds = Subset(full_ds, train_idx)
    val_ds = Subset(full_ds, val_idx)

    train_loader = DataLoader(
        train_ds,
        batch_size=BATCH_SIZE,
        shuffle=True,
        collate_fn=collate_fn_mpnet,
        num_workers=NUM_WORKERS, # üí° T·ªêI ∆ØU
        pin_memory=True          # üí° T·ªêI ∆ØU: TƒÉng t·ªëc chuy·ªÉn data sang GPU
    )
    val_loader = DataLoader(
        val_ds,
        batch_size=BATCH_SIZE * 2, # Th∆∞·ªùng c√≥ th·ªÉ tƒÉng batch_size khi eval
        shuffle=False,
        collate_fn=collate_fn_mpnet,
        num_workers=NUM_WORKERS, # üí° T·ªêI ∆ØU
        pin_memory=True
    )

    # --------------------------
    # Build model
    # --------------------------
    print("Building model...")
    model = EarlyFusionMPNetQA(
        video_dim=VIDEO_FEAT_DIM, # ‚ùó S·ª¨A L·ªñI: D√πng ƒë√∫ng video_dim
        text_dim=768,
        hidden_dim=512
    ).to(device)

    # üí° T·ªêI ∆ØU: (PyTorch 2.0+) TƒÉng t·ªëc model
    if hasattr(torch, 'compile'):
        print("Compiling model (PyTorch 2.0+)...")
        model = torch.compile(model)

    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=LR,
        weight_decay=WEIGHT_DECAY
    )

    # üí° T·ªêI ∆ØU: Kh·ªüi t·∫°o loss function 1 l·∫ßn
    # D√πng ignore_index=-1 ƒë·ªÉ t·ª± ƒë·ªông b·ªè qua c√°c sample kh√¥ng c√≥ label
    loss_fn = nn.CrossEntropyLoss(ignore_index=-1)

    # üí° T·ªêI ∆ØU: Theo d√µi val_loss (·ªïn ƒë·ªãnh h∆°n)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',     # Theo d√µi val_loss (thay v√¨ max cho acc)
        factor=0.5,
        patience=1,
        verbose=True
    )

    scaler = GradScaler(enabled=USE_FP16)

    # --------------------------
    # Training loop
    # --------------------------
    best_val_loss = float('inf')
    epochs_no_improve = 0
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    print(f"--- Starting training ---")
    print(f"Device: {device}, FP16: {USE_FP16}, Accum Steps: {ACCUM_STEPS}")
    print(f"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}")
    
    for epoch in range(EPOCHS):
        model.train()
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS} train")
        total_loss = 0.0
        
        # ƒê·∫∑t zero_grad ·ªü ƒë·∫ßu v√≤ng l·∫∑p step
        optimizer.zero_grad() 

        for step, batch in enumerate(pbar):
            video = batch["video_feats"].to(device)
            text = batch["text_feats"].to(device)
            labels = batch["labels"].to(device)

            with autocast(enabled=USE_FP16):
                logits = model(video, text)
                loss = loss_fn(logits, labels)
                
                # ‚ùó S·ª¨A L·ªñI: Ph·∫£i scale loss tr∆∞·ªõc khi backward()
                # khi d√πng gradient accumulation
                loss_to_backward = loss / ACCUM_STEPS 

            scaler.scale(loss_to_backward).backward()

            # --- Optimizer step ---
            if (step + 1) % ACCUM_STEPS == 0:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()

            # T√≠ch l≈©y loss (ch∆∞a scale) ƒë·ªÉ log
            total_loss += loss.item()
            avg_loss = total_loss / (step + 1)
            pbar.set_postfix({"loss": f"{avg_loss:.4f}"})

        # --------------------------
        # Evaluate
        # --------------------------
        val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)
        print(f"‚úÖ Epoch {epoch+1} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

        # üí° T·ªêI ∆ØU: Step scheduler d·ª±a tr√™n val_loss
        scheduler.step(val_loss)

        # --------------------------
        # Save best
        # üí° T·ªêI ∆ØU: L∆∞u model d·ª±a tr√™n val_loss
        # --------------------------
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            epochs_no_improve = 0
            save_path = os.path.join(OUTPUT_DIR, "best_model.pt")
            torch.save({
                "model": model.state_dict(),
                "val_loss": val_loss,
                "val_acc": val_acc,
                "epoch": epoch
            }, save_path)
            print(f"üíæ Saved best model! (Val Loss: {best_val_loss:.4f})")
        else:
            epochs_no_improve += 1
            print(f"No improvement for {epochs_no_improve} epoch(s)")
            if epochs_no_improve >= EARLYSTOP_PATIENCE:
                print("‚õî Early stopping triggered!")
                break

    print(f"‚úÖ Training done. Best val_loss: {best_val_loss:.4f}")

# ===========================
# RUN
# ===========================
if __name__ == "__main__":
    train_loop()